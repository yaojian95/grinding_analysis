# 工业生产时序数据多输出预测项目

这是一个基于深度学习模型，用于预测工业生产中溢流细度分布（大于80目和小于200目颗粒比例）的工程项目。项目采用模块化设计，旨在提高代码的可读性、可维护性和可扩展性。为了保持技术栈的一致性，所有深度学习模型（LSTM、Attention-LSTM）均已重构为基于PyTorch实现，并集成了LimiX模型。此外，项目还提供了独立的数据探索与分析模块，并对特征工程进行了深入分析，现在支持更高级的相关性分析方法和PCA特征降维。

## 项目结构

```
industrial_lstm_project/
├── config.py
├── data_loader.py
├── model_builder.py
├── trainer.py
├── visualizer.py
├── exploratory_data_analysis.py # 数据探索与分析模块 (新增互信息、时滞互相关)
├── data_analyzer.py             # 已更新：现在仅作为占位符或未来其他数据处理功能
├── main.py                      # 深度学习模型训练与预测主入口
├── run_eda.py                   # 独立的数据探索与分析运行脚本
├── requirements.txt
└── README.md
```

*   `config.py`: 存储所有项目配置，如数据文件路径、模型超参数、目标变量名称等。**新增了高级相关性分析和PCA降维的配置**。
*   `data_loader.py`: 负责数据的加载、预处理（缺失值处理、归一化）以及将数据转换为LSTM模型或LimiX模型所需的序列格式。**新增了特征工程功能**，包括滞后特征和滚动窗口统计特征的创建。**集成了PCA降维功能**。如果未找到数据文件，会自动生成模拟数据。
*   `model_builder.py`: 负责构建和编译深度学习模型，目前支持传统堆叠LSTM（PyTorch）、基于注意力机制的LSTM（PyTorch）以及LimiX模型。
*   `trainer.py`: 负责模型的训练、评估和预测，针对不同模型类型（PyTorch-based LSTM/Attention-LSTM 和 LimiX）提供不同的处理逻辑。
*   `visualizer.py`: 负责将模型的预测结果进行可视化，并保存图表。
*   `exploratory_data_analysis.py`: 包含描述性统计分析、**Pearson相关性分析、互信息分析、时滞互相关分析**和异常检测功能。
*   `data_analyzer.py`: 已更新，目前仅作为占位符，原有的数据分析功能已迁移至 `exploratory_data_analysis.py`。
*   `main.py`: 项目的深度学习模型训练与预测入口点，协调各个模块的运行流程，并允许用户选择使用的模型。**数据加载阶段会根据配置应用PCA降维**。
*   `run_eda.py`: 独立的数据探索与分析运行脚本，现在会执行所有高级相关性分析。
*   `requirements.txt`: 列出项目所需的所有Python依赖库及其版本。**新增了 `statsmodels` 和 `seaborn` 依赖**。
*   `README.md`: 项目说明文件。

## 准备数据

1.  **数据格式**: 您的数据应为CSV格式。
2.  **时间戳列**: CSV文件的第一列必须是时间戳，且格式能够被Pandas正确解析（例如：`YYYY-MM-DD HH:MM:SS`）。
3.  **特征列**: 其他列应包含您提供的所有工况参数（输入特征）。
4.  **目标列**: 必须包含名为 `磨浮工段1号球磨机旋流器溢流+80目` 和 `磨浮工段1号球磨机旋流器溢流-200目` 的两列作为目标变量。
5.  **文件名**: 将您的数据文件命名为 `industrial_data.csv` 并放置在 `industrial_lstm_project/` 目录下。如果您的文件名不同，请修改 `config.py` 中的 `DATA_FILE` 变量。

**重要提示**：确保您的数据中包含 `磨浮工段1号球磨机旋流器溢流+80目` 和 `磨浮工段1号球磨机旋流器溢流-200目` 这两列，否则模型将无法训练。

**示例数据 (`industrial_data.csv`)**:

```csv
timestamp,磨浮工段1号球磨机砂泵功率,磨浮工段1号球磨机磨机功率,...,磨浮工段1号球磨机旋流器溢流+80目,磨浮工段1号球磨机旋流器溢流-200目
2021-01-01 00:00:00,500.1,100.5,...,0.15,0.78
2021-01-01 01:00:00,502.3,101.2,...,0.14,0.79
...
```

## 环境设置

1.  **克隆项目**: 如果您是通过Git获取项目，请先克隆仓库。
2.  **安装依赖**: 进入项目根目录 `industrial_lstm_project/`，然后使用 `pip` 安装 `requirements.txt` 中列出的所有依赖：

    ```bash
    cd industrial_lstm_project
    pip install -r requirements.txt
    ```
    **注意**: LimiX 库可能需要 `build-essential` 和 `python3-dev` 等系统依赖。如果安装 `limix` 遇到编译错误，请尝试安装这些依赖：
    ```bash
    sudo apt-get update
    sudo apt-get install -y build-essential python3-dev python3.11-dev # 根据您的Python版本安装对应的dev包
    ```
3.  **下载 LimiX 模型**: LimiX 模型需要预先下载。请根据 `config.py` 中 `LIMIX_MODEL_PATH` 的路径，将模型文件下载到指定位置。例如，如果 `LIMIX_MODEL_PATH` 是 `limix_model/LimiX-16M.ckpt`，您需要创建 `limix_model` 文件夹并将模型文件下载到其中。代码中已包含自动下载逻辑，但如果下载失败，您可能需要手动下载。

## 运行项目

项目现在分为两个独立的运行流程：数据探索与分析，以及深度学习模型训练与预测。

### 1. 运行数据探索与分析 (EDA)

在完成数据准备和环境设置后，您可以通过运行 `run_eda.py` 文件来执行数据探索与分析：

```bash
python run_eda.py
```

程序将执行数据加载、描述性统计、**Pearson相关性分析、互信息分析、时滞互相关分析**和异常检测。所有分析结果（包括CSV文件和图表）将保存到 `results/` 目录下。

### 2. 运行深度学习模型训练与预测

在完成数据准备和环境设置后，您可以通过运行 `main.py` 文件来启动深度学习模型的训练与预测流程：

```bash
python main.py
```

程序将依次执行数据加载（包含特征工程和**可选的PCA降维**）、模型构建、训练（或LimiX的few-shot预测）、预测和可视化。在 `main.py` 中，您可以修改 `model_choice` 变量来选择使用的模型：

*   `"lstm"`: 传统堆叠LSTM模型 (PyTorch实现)。
*   `"attention_lstm"`: 基于注意力机制的LSTM模型 (PyTorch实现)。
*   `"limix"`: LimiX模型。

目前默认设置为 `"limix"`。

## 配置调整

您可以通过修改 `config.py` 文件来调整项目的各项配置：

*   `DATA_FILE`: 数据文件名。
*   `TARGET_COLUMNS`: 目标变量的列名。
*   `ALL_INPUT_FEATURES`: 所有可能的输入特征列名。
*   `TIME_STEP`: LSTM模型考虑的历史时间步长。
*   `LSTM_UNITS`: LSTM层中的神经元数量。
*   `DENSE_UNITS`: 全连接层中的神经元数量。
*   `EPOCHS`: 模型训练的轮数。
*   `BATCH_SIZE`: 训练时的批次大小。
*   `TEST_SPLIT`: 训练集和测试集的划分比例。
*   `LIMIX_MODEL_PATH`: LimiX模型文件的本地路径。
*   `LIMIX_INFERENCE_CONFIG`: LimiX推理配置。
*   `PLOT_PATH`: 预测结果图表的保存路径。
*   `MODEL_PATH`: 训练好的PyTorch模型保存路径（LimiX模型是预训练的）。
*   `DESCRIPTIVE_STATS_PATH`: 描述性统计结果的保存路径。
*   `CORRELATION_MATRIX_PATH`: Pearson相关性矩阵的保存路径。
*   `CORRELATION_HEATMAP_PATH`: Pearson相关性热力图的保存路径。
*   **`MUTUAL_INFO_PATH`**: 互信息分析结果的保存路径。
*   **`CROSS_CORRELATION_PLOT_PATH`**: 时滞互相关图的保存路径。
*   `ANOMALY_DETECTION_PLOT_PATH`: 异常检测结果图的保存路径。
*   `ANOMALY_CONTAMINATION`: 异常检测中异常值的比例。
*   `LAG_FEATURES`: 需要创建滞后特征的列名列表。
*   `LAG_STEPS`: 滞后步长列表。
*   `ROLLING_WINDOW_FEATURES`: 需要创建滚动窗口统计特征的列名列表。
*   `ROLLING_WINDOW_SIZE`: 滚动窗口的大小。
*   `ROLLING_WINDOW_STATS`: 滚动窗口统计量列表。
*   **`USE_PCA`**: 是否启用PCA特征降维 (True/False)。
*   **`PCA_N_COMPONENTS`**: PCA保留的主成分数量或方差比例 (例如，0.95表示保留95%的方差)。

## 模拟数据说明

如果 `industrial_data.csv` 文件不存在，`data_loader.py` 会自动生成模拟数据进行演示。请注意，模拟数据仅用于验证项目流程和模型结构，其预测结果不具备实际生产意义。

## 高级数据分析与特征降维

### 1. 高级相关性分析

除了传统的Pearson相关系数（衡量线性关系）外，项目现在提供了以下高级相关性分析方法，以更好地捕捉工业数据中可能存在的复杂关系：

*   **互信息 (Mutual Information, MI)**:
    *   **目的**: 衡量两个变量之间相互依赖的程度，包括**非线性关系**。互信息越大，表示变量之间的依赖性越强。
    *   **应用**: 识别与目标变量具有强非线性依赖的关键输入特征，或发现输入特征之间的复杂交互。
    *   **输出**: `results/mutual_information_scores.csv` 文件，显示输入特征与目标变量的互信息分数。

*   **时滞互相关 (Cross-Correlation Function, CCF)**:
    *   **目的**: 衡量两个时间序列在不同时间滞后下的相关性，揭示一个序列的变化是否滞后于另一个序列的变化，以及滞后多少时间。
    *   **应用**: 理解工业过程中变量之间的动态响应和时间延迟，识别导致目标变量变化的先行指标。
    *   **输出**: `results/cross_correlation_plots__{target}.png` 系列图表，展示不同滞后下的互相关系数。

### 2. 特征降维：主成分分析 (Principal Component Analysis, PCA)

*   **目的**: PCA是一种线性降维技术，通过正交变换将原始数据变换到新的坐标系中，使得新的坐标轴（主成分）是数据方差最大的方向。通过选择少量的主成分，可以在保留大部分信息的同时，显著减少特征的数量。
*   **优势**: 减少冗余、提高模型效率、缓解过拟合、过滤噪声。
*   **配置**: 在 `config.py` 中设置 `USE_PCA = True` 启用PCA，并通过 `PCA_N_COMPONENTS` 控制保留的主成分数量或方差比例。
*   **实现**: 在 `data_loader.py` 的 `load_and_preprocess_data` 函数中实现。如果启用，PCA将在特征工程之后、归一化之前应用。

## 深入分析特征工程

特征工程是机器学习项目中至关重要的一步，尤其对于时序数据。它旨在从原始数据中提取或创建新的特征，以提高模型的预测能力和泛化性能。在工业生产数据中，以下几种特征工程方法尤为重要：

1.  **滞后特征 (Lag Features)**:
    *   **目的**: 捕捉时间序列数据中的历史依赖关系。
    *   **实现**: 在 `data_loader.py` 的 `create_lag_features` 函数中实现。
    *   **配置**: 在 `config.py` 中通过 `LAG_FEATURES` 和 `LAG_STEPS` 列表进行配置。

2.  **滚动窗口统计特征 (Rolling Window Features)**:
    *   **目的**: 捕捉时间序列数据在特定时间窗口内的趋势、波动和聚合信息。
    *   **实现**: 在 `data_loader.py` 的 `create_rolling_window_features` 函数中实现。
    *   **配置**: 在 `config.py` 中通过 `ROLLING_WINDOW_FEATURES`、`ROLLING_WINDOW_SIZE` 和 `ROLLING_WINDOW_STATS` 进行配置。

3.  **时间特征 (Time-based Features)**:
    *   **目的**: 提取时间戳中的周期性信息，如小时、天、周、月、季度、年份等，以及是否是周末、节假日等。
    *   **实现**: 可以在 `data_loader.py` 中，从时间戳列中提取这些特征。例如：`df["hour"] = df.index.hour`。

4.  **交互特征 (Interaction Features)**:
    *   **目的**: 捕捉不同特征之间的组合效应。
    *   **实现**: 可以手动创建，例如 `df["power_flow_interaction"] = df["磨机功率"] * df["给矿处理量"]`。

5.  **多项式特征 (Polynomial Features)**:
    *   **目的**: 引入特征的非线性关系。
    *   **实现**: 使用 `sklearn.preprocessing.PolynomialFeatures`。

**特征工程的实践建议**:

*   **领域知识**: 结合磨矿过程的专业知识，理解各个工况参数的物理意义以及它们之间可能存在的因果关系和滞后效应。这是最有效的特征工程方法。
*   **数据探索**: 利用 `exploratory_data_analysis.py` 中的相关性分析、时序图等工具，识别潜在的重要特征和它们与目标变量的关系。
*   **迭代优化**: 特征工程是一个迭代过程。在初步模型训练后，分析模型的误差，并思考是否可以通过创建新的特征来解决这些误差。
*   **避免特征冗余**: 过多的特征可能导致模型过拟合和计算成本增加。可以使用特征选择技术（如基于模型的重要性、Lasso回归等）来筛选最重要的特征。

通过在 `config.py` 中配置 `LAG_FEATURES`, `LAG_STEPS`, `ROLLING_WINDOW_FEATURES`, `ROLLING_WINDOW_SIZE`, `ROLLING_WINDOW_STATS`，您可以灵活地尝试不同的特征工程策略，以找到最适合您数据的特征组合。

## 进一步优化

*   **特征选择**: 在特征工程后，可以考虑使用特征选择算法（如SelectKBest, RFE, 或基于LimiX的特征重要性）来精简特征集，提高模型效率和泛化能力。
*   **模型架构**: 尝试不同的LSTM层数、神经元数量，或引入Dropout层、Batch Normalization等技术来优化模型性能和防止过拟合。您可以尝试在 `model_builder.py` 中实现其他PyTorch变体（如GRU、Bidirectional LSTM）或结合Transformer模块。
*   **超参数调优**: 使用网格搜索、随机搜索或贝叶斯优化等方法来寻找最佳的模型超参数组合。
*   **模型评估**: 引入更多的评估指标（如MAE, R2-score）来全面衡量模型性能。
*   **部署**: 训练好的模型可以保存并部署到生产环境中，用于实时预测。

